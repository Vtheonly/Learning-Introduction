Perfect, Marshal. Here's a **focused and technical README** just for the part of your app that analyzes subtitles to determine video type. It's written in a structured Markdown format, ready for Obsidian or GitHub.

---

# ğŸ“„ YouTube Subtitles Analyzer â€“ README

## ğŸ” Purpose

This module focuses solely on **analyzing the subtitle (caption) content of YouTube videos** to determine their genre, quality, and relevance for distraction-free consumption. It is the brain of your YouTube Focus App that detects low-value vs. high-value content based on **textual cues**.

---

## ğŸ“ File Structure

```bash
yt-sub-analyzer/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py                # Entry point; orchestrates the analysis
â”‚   â”œâ”€â”€ fetch_subs.py          # Retrieves subtitles using YouTube Data API / scraping
â”‚   â”œâ”€â”€ clean_text.py          # Preprocesses and cleans subtitle text
â”‚   â”œâ”€â”€ classify_content.py    # Applies ML/NLP models to classify the video type
â”‚   â””â”€â”€ utils.py               # Helpers for logging, formatting, etc.
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ genre_classifier.pkl   # Trained ML model for genre classification
â”‚   â””â”€â”€ tfidf_vectorizer.pkl   # Text vectorizer for converting text to features
â”œâ”€â”€ data/
â”‚   â””â”€â”€ stopwords.txt          # Custom stopwords for cleaner classification
â”œâ”€â”€ requirements.txt           # Python dependencies
â””â”€â”€ README.md                  # This file
```

---

## ğŸ§  Pipeline Description

### 1. **Subtitle Extraction**
- **Source**: YouTube Captions (Auto or Manual)
- **Methods**:
  - Uses `youtube_transcript_api` or YouTube API (where available)
  - Fallback to scraping for unavailable captions

### 2. **Text Cleaning**
- Lowercasing, punctuation stripping, number removal
- Stopword filtering (NLTK + domain-specific terms)
- Optional: Lemmatization (via SpaCy)

### 3. **Feature Engineering**
- TF-IDF Vectorization
- Word Embeddings (Word2Vec, GloVe, or BERT for advanced analysis)

### 4. **Classification**
- **Model**: Pre-trained Logistic Regression or Transformer model
- **Labels (examples)**:
  - ğŸ§  `educational`
  - ğŸ•¹ï¸ `entertainment`
  - ğŸ§˜ `mindless`
  - ğŸ­ `motivational`
  - ğŸ¬ `shorts`
  - ğŸ’ `low-effort clickbait`
  - ğŸ“° `news / commentary`
- Confidence score assigned per label

---

## ğŸš¨ YouTube Policy Considerations

> âš ï¸ *The following features might trigger YouTube's detection systems or violate terms of service:*

| Feature | Risk Level | Description |
|--------|------------|-------------|
| Fetching subtitles without API | ğŸ”´ High | Scraping auto-captions may violate ToS |
| Emulating watch behavior | ğŸ”´ High | Marking videos as "watched" without viewing may violate behavior policies |
| Auto-interaction with YouTube (e.g., dislike/remove/like) | ğŸŸ  Medium | Automated interaction bots are against YouTube's terms |
| Using third-party APIs to emulate progress bar | ğŸŸ  Medium | YouTube Player API doesn't officially allow modifying watch progress directly |
| Hosting analysis results publicly with video links | ğŸŸ¡ Low | Might be flagged under privacy or content redistribution policies |

---

## ğŸ“Œ Legal Gray Areas

YouTube's [Terms of Service](https://www.youtube.com/t/terms) prohibit:

- Automated scraping or data extraction unless using official APIs
- Circumventing or manipulating watch history to influence the algorithm
- Interacting with video elements (likes/dislikes/history) via automation

> â—Use this module for **personal use**, **educational research**, or with **user consent** to avoid violating YouTube policies.

---

## ğŸ§ª Testing

You can run this module independently:

```bash
# Fetch subs and classify
python src/main.py --video_id=<YouTubeVideoID>
```

Expected output:

```bash
Video ID: dQw4w9WgXcQ
Subtitle Length: 2381 tokens
Classified As: entertainment (87% confidence)
```

---

## âœ… Dependencies

```txt
youtube_transcript_api
scikit-learn
nltk
spacy
joblib
numpy
```

---

## ğŸ§­ Future Improvements

- Add semantic similarity scoring with educational content
- Integrate live subtitle extraction while video is playing
- Allow custom label training by user

---

Let me know when you're ready for a legal/ethical breakdown that you can feed to a Google-based LLM or lawyer-style AI. Weâ€™ll dig deeper into scraping legality, fair use, user simulation, and possibly even machine ethics if you're planning long-term deployment.